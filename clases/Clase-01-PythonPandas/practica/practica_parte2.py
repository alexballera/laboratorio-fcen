#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
@author: Alex Ballera
https://docs.python.org/es/3.14/library/index.html
https://pandas.pydata.org/docs/reference/index.html
https://numpy.org/doc/stable/reference/index.html
https://docs.python.org/es/3.14/library/collections.html#
"""
# %% Importo las librer√≠as
import pandas as pd
# %% preparacion_df
# ============================================================================
# VERSI√ìN ANTERIOR:
# ============================================================================
# def preparacion_df(path):
#     arboles_veredas = pd.read_csv(path)
#     df = pd.DataFrame(arboles_veredas)  # ‚ùå REDUNDANTE: pd.read_csv ya retorna DataFrame
#     
#     data_arboles_veredas = df[['nombre_cientifico', 'ancho_acera', 'diametro_altura_pecho']]
#     return data_arboles_veredas, df
# ============================================================================

# VERSI√ìN OPTIMIZADA:
def preparacion_df(path):
    """Carga datos de arbolado desde CSV y retorna subconjunto de columnas.
    
    MEJORA: Elimina conversi√≥n redundante pd.DataFrame() - read_csv() ya retorna DataFrame.
    
    CONCEPTO: No duplicar trabajo - read_csv retorna un DataFrame, no necesita conversi√≥n.
    Hacer esto es como convertir un int a int: innecesario y confuso.
    
    Args:
        path: Ruta al archivo CSV (local o URL)
        
    Returns:
        tuple: (data_arboles_veredas con 3 columnas, df completo)
    """
    # pd.read_csv ya retorna un DataFrame - no necesita conversi√≥n
    df = pd.read_csv(path)
    
    # Seleccionar columnas de inter√©s
    data_arboles_veredas = df[['nombre_cientifico', 'ancho_acera', 'diametro_altura_pecho']]
    return data_arboles_veredas, df

# %% ejercicio 8
# ============================================================================
# VERSI√ìN ANTERIOR (C√ìDIGO PROBLEM√ÅTICO):
# ============================================================================
# def parques_veredas_df():
#     # ‚ùå PROBLEMA CR√çTICO 1: Usa variable global 'df' - funci√≥n NO aut√≥noma
#     #    Si 'df' no existe o cambia externamente, la funci√≥n falla o da resultados incorrectos
#     arboles = df[['nombre_cientifico', 'diametro_altura_pecho', 'altura_arbol', 'ancho_acera']]
#     
#     # ‚ùå PROBLEMA 2: Compara string con string - 'ancho_acera' > '0'
#     #    Esto NO funciona correctamente porque:
#     #    - Si ancho_acera es num√©rico (float), falla con TypeError
#     #    - Si es string, compara alfab√©ticamente: '10' < '2' (incorrecto)
#     vereda = arboles[arboles['ancho_acera'] > '0']
#     
#     # ‚ùå PROBLEMA 3: Selecciona columnas DESPU√âS de filtrar
#     #    Ineficiente - carga datos que luego descarta
#     parque = arboles[arboles['ancho_acera'].isna()]
#     
#     vereda = vereda[['nombre_cientifico', 'diametro_altura_pecho', 'altura_arbol']]
#     parque = parque[['nombre_cientifico', 'diametro_altura_pecho', 'altura_arbol']]
#
#     return parque, vereda
# ============================================================================

# VERSI√ìN OPTIMIZADA:
def parques_veredas_df(df):
    """Separa √°rboles en parques vs veredas seg√∫n presencia de ancho_acera.
    
    MEJORAS CR√çTICAS:
    1. Recibe 'df' como par√°metro - funci√≥n pura, sin dependencias globales
    2. Compara num√©ricamente (> 0) en lugar de string (> '0')
    3. Usa .copy() para evitar SettingWithCopyWarning
    
    CONCEPTOS CLAVE:
    
    CONCEPTO 1: Variables globales son ANTIPATR√ìN
    - ‚ùå Funci√≥n que usa global 'df' ‚Üí acoplamiento, dif√≠cil de testear
    - ‚úÖ Funci√≥n con par√°metro 'df' ‚Üí reutilizable, testeable, clara
    
    CONCEPTO 2: Comparaci√≥n num√©rica vs string
    - ‚ùå '10' > '2' retorna False (compara alfab√©ticamente)
    - ‚úÖ  10 > 2 retorna True (compara num√©ricamente)
    - pd.to_numeric convierte strings a float, maneja errores con coerce
    
    CONCEPTO 3: .copy() evita SettingWithCopyWarning
    - Cuando haces df[condicion], pandas puede retornar vista o copia
    - Modificar vista puede afectar el DataFrame original sin querer
    - .copy() garantiza DataFrame independiente
    
    CONCEPTO 4: Separaci√≥n l√≥gica clara
    - Vereda: ancho_acera > 0 (tiene vereda medible)
    - Parque: ancho_acera es NaN (no tiene vereda, est√° en parque)
    
    Args:
        df: DataFrame con datos completos de arbolado
        
    Returns:
        tuple: (df_parque, df_vereda) ambos con columnas [nombre_cientifico, 
                diametro_altura_pecho, altura_arbol]
    """
    # Validaci√≥n de entrada - defensive programming
    if df is None or df.empty:
        # CONCEPTO: Crear una sola estructura vac√≠a y retornarla dos veces
        # as√≠ que es seguro retornar la misma referencia.
        # NOTA: Si necesit√°ramos modificar los DataFrames despu√©s, S√ç deber√≠amos
        # crear copias separadas con .copy()
        columnas = ['nombre_cientifico', 'diametro_altura_pecho', 'altura_arbol']
        df_vacio = pd.DataFrame(columns=columnas)
        return df_vacio, df_vacio  # Misma referencia - m√°s eficiente en memoria
    
    # Convertir ancho_acera a num√©rico (maneja strings, NaN, etc.)
    # coerce=True convierte valores inv√°lidos a NaN en lugar de lanzar error
    df_trabajo = df.copy()  # Trabajar con copia para no modificar original
    df_trabajo['ancho_acera_num'] = pd.to_numeric(df_trabajo['ancho_acera'], errors='coerce')
    
    # Seleccionar columnas de inter√©s primero (m√°s eficiente)
    columnas_finales = ['nombre_cientifico', 'diametro_altura_pecho', 'altura_arbol']
    
    # FILTRO VEREDAS: ancho_acera > 0 (tiene vereda medible)
    # Nota: .notna() asegura que no incluimos NaN
    mascara_vereda = (df_trabajo['ancho_acera_num'].notna()) & (df_trabajo['ancho_acera_num'] > 0)
    df_vereda = df_trabajo.loc[mascara_vereda, columnas_finales].copy()
    
    # FILTRO PARQUES: ancho_acera es NaN (sin vereda ‚Üí en parque)
    mascara_parque = df_trabajo['ancho_acera_num'].isna()
    df_parque = df_trabajo.loc[mascara_parque, columnas_finales].copy()
    
    return df_parque, df_vereda

# %% Ejercicio 9
# ============================================================================
# VERSI√ìN ANTERIOR (C√ìDIGO PROBLEM√ÅTICO):
# ============================================================================
# def add_column_ambiente(df_parque, df_vereda):
#     # ‚ùå PROBLEMA 1: Sintaxis incorrecta - doble corchete [['ambiente']] para asignar
#     #    Deber√≠a ser ['ambiente'] (sin lista) para asignar a una columna
#     #    El doble corchete se usa para SELECCIONAR m√∫ltiples columnas, no para asignar
#     df_parque[['ambiente']] = 'parque'
#     df_vereda[['ambiente']] = 'vereda'
#     
#     # ‚ùå PROBLEMA 2: Modifica los DataFrames originales (mutaci√≥n in-place)
#     #    Si los DataFrames se usan despu√©s, tienen efectos secundarios no deseados
#     #    Viola el principio de funciones puras
#     
#     return df_parque, df_vereda
# ============================================================================

# VERSI√ìN OPTIMIZADA:
def add_column_ambiente(df_parque, df_vereda):
    """A√±ade columna 'ambiente' a DataFrames de parque y vereda.
    
    MEJORAS CR√çTICAS:
    1. Usa .copy() para no modificar los DataFrames originales (inmutabilidad)
    2. Sintaxis correcta: ['ambiente'] en lugar de [['ambiente']]
    3. Usa .assign() como alternativa pyth√≥nica (m√©todo funcional)
    
    CONCEPTOS CLAVE:
    
    CONCEPTO 1: Inmutabilidad - funciones puras
    - ‚ùå Modificar par√°metros in-place ‚Üí efectos secundarios, dif√≠cil de debuggear
    - ‚úÖ Retornar nuevos objetos ‚Üí predecible, testeable, sin sorpresas
    
    CONCEPTO 2: Sintaxis de pandas para columnas
    - df[['col1', 'col2']]  ‚Üí SELECCIONAR m√∫ltiples columnas (retorna DataFrame)
    - df['col']             ‚Üí SELECCIONAR/ASIGNAR una columna (Series o asignaci√≥n)
    - df[['col']] = valor   ‚Üí INCORRECTO (funciona pero no es la forma id√≥nea)
    - df['col'] = valor     ‚Üí CORRECTO (asignaci√≥n directa)
    
    CONCEPTO 3: .assign() - m√©todo funcional de pandas
    - Sintaxis: df.assign(nueva_col=valor)
    - Retorna NUEVO DataFrame sin modificar el original
    - M√°s pyth√≥nico y encadenable (method chaining)
    
    Args:
        df_parque: DataFrame con √°rboles de parques
        df_vereda: DataFrame con √°rboles de veredas
        
    Returns:
        tuple: (df_parque_con_ambiente, df_vereda_con_ambiente)
    """
    # OPCI√ìN 1: Usar .copy() y asignaci√≥n directa (m√°s expl√≠cito)
    df_parque_nuevo = df_parque.copy()
    df_vereda_nuevo = df_vereda.copy()
    
    # Sintaxis correcta: ['ambiente'] sin doble corchete
    df_parque_nuevo['ambiente'] = 'parque'
    df_vereda_nuevo['ambiente'] = 'vereda'
    
    return df_parque_nuevo, df_vereda_nuevo
    
    # OPCI√ìN 2: Usar .assign() - m√°s funcional y pyth√≥nico
    # return (
    #     df_parque.assign(ambiente='parque'),
    #     df_vereda.assign(ambiente='vereda')
    # )
    # Ventaja: m√°s conciso, inmutable por defecto, encadenable

# %% Ejercicio 10
# ============================================================================
# VERSI√ìN ANTERIOR (B√ÅSICA):
# ============================================================================
# def concatenar(df_parque, df_vereda):
#     # ‚ùå PROBLEMA 1: No valida entrada (DataFrames vac√≠os o None)
#     # ‚ùå PROBLEMA 2: No maneja √≠ndices duplicados - puede causar problemas
#     # ‚ùå PROBLEMA 3: No especifica par√°metros importantes de concat
#     #    - ignore_index: si no se especifica, mantiene √≠ndices originales (puede duplicar)
#     #    - axis: por defecto es 0 (filas), pero ser expl√≠cito es mejor
#     return pd.concat([df_parque, df_vereda])
# ============================================================================

# VERSI√ìN OPTIMIZADA:
def concatenar(df_parque, df_vereda):
    """Concatena verticalmente DataFrames de parque y vereda.
    
    MEJORAS:
    1. Valida entrada - maneja DataFrames vac√≠os o None
    2. Usa ignore_index=True para resetear √≠ndices (evita duplicados)
    3. Especifica axis=0 expl√≠citamente (mejor legibilidad)
    
    CONCEPTOS CLAVE:
    
    CONCEPTO 1: pd.concat() - uni√≥n de DataFrames
    - axis=0 (default) ‚Üí concatena VERTICALMENTE (a√±ade filas)
    - axis=1 ‚Üí concatena HORIZONTALMENTE (a√±ade columnas)
    - ignore_index=True ‚Üí resetea √≠ndices (0, 1, 2, ..., n)
    - ignore_index=False (default) ‚Üí mantiene √≠ndices originales (puede duplicar)
    
    CONCEPTO 2: √çndices duplicados son problem√°ticos
    - Si df1 tiene √≠ndices [0,1,2] y df2 tiene [0,1,2]
    - concat sin ignore_index ‚Üí resultado tiene [0,1,2,0,1,2] (duplicados)
    - .loc[0] retorna M√öTIPLES filas - comportamiento confuso
    - ignore_index=True ‚Üí resultado tiene [0,1,2,3,4,5] (sin duplicados)
    
    CONCEPTO 3: Validaci√≥n defensiva con listas
    - Filtrar DataFrames v√°lidos antes de concat
    - Evita errores si alguno es None o vac√≠o
    - Retorna DataFrame vac√≠o con estructura correcta si no hay datos
    
    Args:
        df_parque: DataFrame con √°rboles de parques (con columna 'ambiente')
        df_vereda: DataFrame con √°rboles de veredas (con columna 'ambiente')
        
    Returns:
        DataFrame: Uni√≥n vertical de ambos DataFrames con √≠ndice reseteado
    """
    # Validaci√≥n defensiva - construir lista de DataFrames v√°lidos
    dfs_validos = []
    
    if df_parque is not None and not df_parque.empty:
        dfs_validos.append(df_parque)
    if df_vereda is not None and not df_vereda.empty:
        dfs_validos.append(df_vereda)
    
    # Si no hay DataFrames v√°lidos, retornar DataFrame vac√≠o con estructura
    if not dfs_validos:
        # Inferir columnas del primer DataFrame no vac√≠o, o usar estructura b√°sica
        columnas = ['nombre_cientifico', 'diametro_altura_pecho', 'altura_arbol', 'ambiente']
        return pd.DataFrame(columns=columnas)
    
    # Concatenar verticalmente (axis=0) reseteando √≠ndices
    # ignore_index=True ‚Üí evita √≠ndices duplicados, crea secuencia 0,1,2,...,n
    return pd.concat(
        dfs_validos,
        axis=0,              # Concatenar verticalmente (a√±adir filas)
        ignore_index=True    # Resetear √≠ndices para evitar duplicados
    )

# %% Ejercicio 11
def analizar_diferencias_por_ambiente(df_concatenado, especies_seleccionadas):
    """Analiza diferencias entre ejemplares de especies seg√∫n ambiente (parque vs vereda).
    
    Responde: ¬øHay diferencias entre ejemplares de una misma especie seg√∫n si crecen 
    en un parque o en la vereda?
    
    CONCEPTOS CLAVE:
    
    CONCEPTO 1: .groupby() - agrupa filas y calcula estad√≠sticas por grupo
    - df.groupby(['especie', 'ambiente'])['diametro'].mean()
    
    CONCEPTO 2: .isin() - filtra filas por lista de valores
    - df[df['especie'].isin(['A', 'B', 'C'])]
    
    CONCEPTO 3: .pivot_table() - reorganiza datos (largo ‚Üí ancho) para comparar
    - Convierte ambiente en columnas (parque | vereda)
    
    Args:
        df_concatenado: DataFrame con √°rboles de parques y veredas
        especies_seleccionadas: Lista de especies a analizar
        
    Returns:
        DataFrame: Comparaci√≥n lado a lado (parque vs vereda) con diferencias %
    """
    # Filtrar por especies de inter√©s
    mascara = df_concatenado['nombre_cientifico'].isin(especies_seleccionadas)
    df_filtrado = df_concatenado[mascara].copy()
    
    # Convertir a num√©rico (previene errores)
    df_filtrado['diametro_altura_pecho'] = pd.to_numeric(
        df_filtrado['diametro_altura_pecho'], errors='coerce'
    )
    df_filtrado['altura_arbol'] = pd.to_numeric(
        df_filtrado['altura_arbol'], errors='coerce'
    )
    
    # Calcular promedios por especie y ambiente
    promedios = df_filtrado.groupby(['nombre_cientifico', 'ambiente']).agg({
        'diametro_altura_pecho': 'mean',
        'altura_arbol': 'mean'
    }).round(2)
    
    # Reorganizar para comparar lado a lado (pivot)
    # De formato largo ‚Üí ancho (parque y vereda como columnas)
    comparacion = promedios.reset_index().pivot(
        index='nombre_cientifico',
        columns='ambiente',
        values=['diametro_altura_pecho', 'altura_arbol']
    )
    
    # Calcular diferencias porcentuales: (vereda - parque) / parque * 100
    # Esto muestra si en vereda hay +% o -% respecto al parque
    for metrica in ['diametro_altura_pecho', 'altura_arbol']:
        if ('parque' in comparacion[metrica].columns and 
            'vereda' in comparacion[metrica].columns):
            comparacion[(metrica, 'dif_%')] = (
                (comparacion[(metrica, 'vereda')] - comparacion[(metrica, 'parque')]) / 
                comparacion[(metrica, 'parque')] * 100
            ).round(1)
    
    return comparacion

# %% main
if __name__ == '__main__':
    path1 = 'https://cdn.buenosaires.gob.ar/datosabiertos/datasets/atencion-ciudadana/arbolado-publico-lineal/arbolado-publico-lineal-2017-2018.csv'
    path2 = '/home/alexballera/Documents/uba/laboratorio-fcen/clases/Clase-01-PythonPandas/practica/arbolado-publico-lineal-2017-2018.csv'
    especies_seleccionadas = ['Tilia x moltkei', 'Jacaranda mimosifolia', 'Tipuana tipu']
    
    # preparacion_df
    data_arboles_veredas, df = preparacion_df(path2)

    # Ejercicio 8
    print('='*60)
    # Pasar 'df' como par√°metro - funci√≥n pura sin dependencias globales
    df_tipas_parques, df_tipas_veredas = parques_veredas_df(df)
    
    # Verificar resultados
    print(f"√Årboles en parques: {len(df_tipas_parques)}")
    print(f"√Årboles en veredas: {len(df_tipas_veredas)}")
    print("\nPrimeros 3 √°rboles en parques:")
    print(df_tipas_parques.head(3))
    print("\nPrimeros 3 √°rboles en veredas:")
    print(df_tipas_veredas.head(3))
    
    # Ejercicio 9
    print('='*60)
    print('Ejercicio 9')
    df_tipas_parques, df_tipas_veredas = add_column_ambiente(df_tipas_parques, df_tipas_veredas)
    
    # Verificar resultados
    print(f"Columnas en parques: {df_tipas_parques.columns}")
    print(f"Columnas en veredas: {df_tipas_veredas.columns}")
    print("\nPrimeros 3 √°rboles en parques:")
    print(df_tipas_parques.head(3))
    print("\nPrimeros 3 √°rboles en veredas:")
    print(df_tipas_veredas.head(3))
    
    # Ejercicio 10
    print('='*60)
    print('Ejercicio 10')
    df_concatenado = concatenar(df_tipas_parques, df_tipas_veredas)
    
    # Verificar resultados
    print(f"Columnas en nuevo df: {df_concatenado.columns}")
    print("\nPrimeros 3 √°rboles:")
    print(df_concatenado.head(3))
    print("\n√öltimos 3 √°rboles:")
    print(df_concatenado.tail(3))
    
    # Ejercicio 11
    print('='*60)
    print('Ejercicio 11: An√°lisis parque vs vereda')
    print('='*60)
    
    comparacion = analizar_diferencias_por_ambiente(df_concatenado, especies_seleccionadas)
    
    print("\nüìä COMPARACI√ìN POR ESPECIE (promedios):")
    print(comparacion)
    
    print("\nüìù INTERPRETACI√ìN:")
    for especie in especies_seleccionadas:
        if especie in comparacion.index:
            print(f"\nüå≥ {especie}:")
            
            # Diferencia % de di√°metro
            if ('diametro_altura_pecho', 'dif_%') in comparacion.columns:
                dif_diam = comparacion.loc[especie, ('diametro_altura_pecho', 'dif_%')]
                if pd.notna(dif_diam):
                    if abs(dif_diam) < 5:
                        print(f"  ‚Ä¢ Di√°metro similar en ambos ambientes ({dif_diam:+.1f}%)")
                    else:
                        ambiente = "vereda" if dif_diam > 0 else "parque"
                        print(f"  ‚Ä¢ Di√°metro mayor en {ambiente} ({dif_diam:+.1f}%)")
            
            # Diferencia % de altura
            if ('altura_arbol', 'dif_%') in comparacion.columns:
                dif_alt = comparacion.loc[especie, ('altura_arbol', 'dif_%')]
                if pd.notna(dif_alt):
                    if abs(dif_alt) < 5:
                        print(f"  ‚Ä¢ Altura similar en ambos ambientes ({dif_alt:+.1f}%)")
                    else:
                        ambiente = "vereda" if dif_alt > 0 else "parque"
                        print(f"  ‚Ä¢ Altura mayor en {ambiente} ({dif_alt:+.1f}%)")
    
    

# %%